{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Document Summarization with SmolAgent & LLM Guardrails\n",
    "\n",
    "**This notebook extracts text from a financial PDF, summarizes it using SmolAgent's CodeAgent, performs self-evaluation, and validates accuracy using a locally hosted OpenAI-compatible LLM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smolagent requests openai pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 2: Import Dependencies & Set Up Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "import pypdf  # For PDF text extraction\n",
    "from smolagent import CodeAgent\n",
    "\n",
    "# Configure OpenAI-compatible local LLM\n",
    "openai.api_base = \"http://127.0.0.1:1234/v1\"  # Local model\n",
    "openai.api_key = \"sk-local\"  # Dummy key since local models don't need authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 3: Extract Text from a PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a financial PDF document.\"\"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        pdf_reader = pypdf.PdfReader(file)\n",
    "        text = \"\\n\".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])\n",
    "    return text\n",
    "\n",
    "# Load financial document (update the file path)\n",
    "pdf_path = \"financial_report.pdf\"  # Change to your file path\n",
    "financial_document = extract_text_from_pdf(pdf_path)\n",
    "print(\"Extracted Document Snippet:\\n\", financial_document[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 4: Create SmolAgent for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_agent = CodeAgent(name=\"FinancialSummarizer\", llm=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 5: Generate a Summary Using SmolAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Write a Python script that extracts key financial figures (e.g., revenue, net income, EBITDA) and risk disclosures\n",
    "from the following financial report and summarizes them concisely:\n",
    "\n",
    "{financial_document[:2000]}\n",
    "\"\"\"\n",
    "\n",
    "summary_code = summarization_agent.run(prompt)\n",
    "print(\"Generated Code:\\n\", summary_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 6: Self-Evaluate the Generated Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate_summary(summary, source_text):\n",
    "    \"\"\"Check completeness and consistency.\"\"\"\n",
    "    checks = {\n",
    "        \"contains_financials\": any(keyword in summary.lower() for keyword in [\"revenue\", \"net income\", \"ebitda\", \"profit\"]),\n",
    "        \"contains_risk_factors\": \"risk\" in summary.lower(),\n",
    "        \"word_count\": len(summary.split()) < 250,\n",
    "        \"matches_source\": any(phrase in source_text for phrase in summary.split()[:10])\n",
    "    }\n",
    "    return all(checks.values()), checks\n",
    "\n",
    "self_eval_passed, self_eval_checks = self_evaluate_summary(summary_code, financial_document)\n",
    "print(\"\\nSelf-Evaluation Passed:\", self_eval_passed)\n",
    "print(\"Self-Evaluation Checks:\", self_eval_checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 7: Use an LLM Guardrail to Verify Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardrail_evaluate(summary, source_text):\n",
    "    \"\"\"Evaluate summary accuracy.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Evaluate this financial summary against the source document.\n",
    "    Summary:\n",
    "    {summary}\n",
    "    \n",
    "    Source:\n",
    "    {source_text[:3000]}\n",
    "    \n",
    "    Return a confidence score (0-100) and an explanation.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-4\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "guardrail_score = guardrail_evaluate(summary_code, financial_document)\n",
    "print(\"\\nðŸ” Guardrail Score:\", guardrail_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
